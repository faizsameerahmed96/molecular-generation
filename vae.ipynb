{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50bcc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7654221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "smiles_list = df['SMILES'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a351b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize SMILES strings (character-level )\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(smiles):\n",
    "    return list(smiles)  # character-level\n",
    "\n",
    "tokens = [token for s in smiles_list for token in tokenize(s)]\n",
    "vocab = ['<pad>', '<bos>', '<eos>', '<unk>'] + sorted(set(tokens))\n",
    "stoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "itos = {i: ch for ch, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38c5e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 60\n",
    "\n",
    "def encode(smiles):\n",
    "    tokens = ['<bos>'] + tokenize(smiles) + ['<eos>']\n",
    "    idxs = [stoi.get(t, stoi['<unk>']) for t in tokens]\n",
    "    idxs = idxs[:MAX_LEN] + [stoi['<pad>']] * (MAX_LEN - len(idxs))\n",
    "    return idxs\n",
    "\n",
    "input_tensor = torch.tensor([encode(s) for s in smiles_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d458e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        h = h[-1]  # last layer hidden state\n",
    "        return self.fc_mu(h), self.fc_logvar(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c6c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5abb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.fc = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        h = torch.tanh(self.fc(z)).unsqueeze(0)\n",
    "        c = torch.zeros_like(h)\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x, (h, c))\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e639d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=256, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, emb_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(vocab_size, emb_dim, hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z, x[:, :-1])  # teacher forcing\n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2981f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_logits, x, mu, logvar):\n",
    "    recon_loss = nn.CrossEntropyLoss(ignore_index=stoi['<pad>'])(recon_logits.view(-1, recon_logits.size(-1)), x[:, 1:].contiguous().view(-1))\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    return recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f15570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24761 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24761/24761 [05:55<00:00, 69.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.6055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = VAE(len(vocab)).to(\"mps\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "dataset = TensorDataset(input_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch, in tqdm(loader):\n",
    "        batch = batch.to(\"mps\")\n",
    "        optimizer.zero_grad()\n",
    "        recon_logits, mu, logvar = model(batch)\n",
    "        loss = vae_loss(recon_logits, batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}: Loss = {total_loss / len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00de86ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent vector z: tensor([[ 0.5367, -1.1114,  0.3204, -2.7990, -0.4941, -1.2613,  0.6209, -0.0722,\n",
      "         -1.5696,  2.1767,  0.7549, -0.8277,  1.2693, -0.4947, -0.0656,  2.2062,\n",
      "         -0.6120,  0.3245, -1.0779, -0.2699,  0.0936,  1.0524, -0.3196,  0.3275,\n",
      "         -0.2393, -0.8876,  0.8789,  0.9816,  0.2032,  0.2390, -0.6276,  0.1032,\n",
      "         -0.9381, -0.5492, -0.6289,  0.2948, -1.2225, -0.7944, -1.4701, -0.2657,\n",
      "         -0.1899,  1.2341,  0.3867, -0.0350, -2.1999, -1.1844, -1.2625,  0.9390,\n",
      "         -1.6533, -0.7387,  2.9420,  0.6933,  0.0176,  0.4217, -0.6841,  0.5865,\n",
      "          0.6801, -1.1861, -1.3386,  0.9958, -0.2431, -1.9837, -0.0599, -0.2664]],\n",
      "       device='mps:0')\n",
      "Generated SMILES: CC(C)(C)OC(=O)N1CCC(NC(=O)c2ccccc2)CC1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1, 64).to(\"mps\")\n",
    "    print(\"Latent vector z:\", z)\n",
    "    start_token = torch.tensor([[stoi['<bos>']]]).to(\"mps\")\n",
    "    generated = [start_token]\n",
    "    \n",
    "    for _ in range(MAX_LEN):\n",
    "        inp = torch.cat(generated, dim=1)\n",
    "        logits = model.decoder(z, inp)\n",
    "        next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        generated.append(next_token)\n",
    "        if next_token.item() == stoi['<eos>']:\n",
    "            break\n",
    "\n",
    "    decoded = ''.join([itos[t.item()] for t in torch.cat(generated, dim=1)[0] if t.item() not in [stoi['<bos>'], stoi['<eos>'], stoi['<pad>']]])\n",
    "    print(\"Generated SMILES:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56bff9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid molecule!\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "mol = Chem.MolFromSmiles(decoded)\n",
    "if mol:\n",
    "    print(\"Valid molecule!\")\n",
    "else:\n",
    "    print(\"Invalid SMILES.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd31fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
